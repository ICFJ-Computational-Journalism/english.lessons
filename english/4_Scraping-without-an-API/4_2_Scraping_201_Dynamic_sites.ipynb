{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-6r-c23G-kh"
      },
      "source": [
        "## Introduction to Selenium: An overview of what Selenium is, what it can do, and its use cases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3IbKnEKIC2Q"
      },
      "source": [
        "I am excited to introduce you to Selenium, which opens up new possibilities for web scraping.\n",
        "\n",
        "When you want to extract data from a webpage that doesn't require user interaction, you can use the Requests library to send an HTTP request to the webpage and retrieve the HTML content. You can then use Beautiful Soup to parse the HTML and extract the relevant information. However, if the webpage requires user interaction, such as clicking a button or filling out a form, you'll need to use a tool like Selenium to automate these interactions and scrape the data. So, you can use Requests and Beautiful Soup for static webpages that don't require user interaction, and but you need to use Selenium for dynamic webpages that require user interaction.\n",
        "\n",
        "Let's say you want to scrape a website that requires you to log in before you can access the content you want to scrape. In this case, you would need to use Selenium to automate the login process and scrape the data. Using Requests and Beautiful Soup won't work in this case, as you need to submit a login form with your username and password, which requires user interaction. With Selenium, you can automate the login process by navigating to the login page, entering your credentials, and submitting the login form. Once you're logged in, you can then use Selenium to navigate to the pages with the content you want to scrape and use Beautiful Soup to extract the relevant information.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8V-hJ0-Loi4"
      },
      "source": [
        "#### Project Possibilities\n",
        "We provide you with some specific ideas of the possibilities that Selenium can open up in your investigative research\n",
        "\n",
        "1. Investigating government corruption: To investigate government corruption in Iran, a journalist might use Selenium to scrape government websites and procurement portals to collect information on government contracts, bids, and transactions. Selenium could be used to simulate user interactions with these websites, such as navigating through menus, filling out search forms, and downloading data files.\n",
        "\n",
        "2. Mapping social and political movements: To map social and political movements in Iran, a journalist might use Selenium to scrape social media platforms, such as Twitter or Facebook, to collect data on user activities, hashtags, and mentions. Selenium could be used to simulate user interactions with these platforms, such as logging in, searching for keywords, and scrolling through feeds.\n",
        "\n",
        "3. Tracking environmental issues: To track environmental issues in Iran, a journalist might use Selenium to scrape websites that provide environmental data, such as weather forecasts or air quality reports. Selenium could be used to simulate user interactions with these websites, such as selecting locations, dates, and types of data.\n",
        "\n",
        "4. Analyzing economic trends: To analyze economic trends in Iran, a journalist might use Selenium to scrape financial data from websites, such as stock market data or economic indicators. Selenium could be used to simulate user interactions with these websites, such as selecting dates, time periods, and types of data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtSmrN1CHA83"
      },
      "source": [
        "#### Setting up the Selenium environment: How to install and configure the Selenium framework, including the Selenium WebDriver, which allows you to automate interactions with a web page.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sl8_In9fJiZF"
      },
      "source": [
        "You can install Selenium using pip, which is Python's package manager. We use the following command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6ffoF_OJkB_",
        "outputId": "4ec1615e-e567-4b8b-c0bf-9d7637b64464"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-4.9.1-py3-none-any.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2021.10.8 in /Users/jacobwaldor/mambaforge/lib/python3.9/site-packages (from selenium) (2022.9.24)\n",
            "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /Users/jacobwaldor/mambaforge/lib/python3.9/site-packages (from selenium) (1.26.9)\n",
            "Collecting trio~=0.17\n",
            "  Downloading trio-0.22.0-py3-none-any.whl (384 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.9/384.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting trio-websocket~=0.9\n",
            "  Downloading trio_websocket-0.10.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: sortedcontainers in /Users/jacobwaldor/mambaforge/lib/python3.9/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Collecting async-generator>=1.9\n",
            "  Using cached async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: sniffio in /Users/jacobwaldor/mambaforge/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.3.0)\n",
            "Collecting exceptiongroup>=1.0.0rc9\n",
            "  Downloading exceptiongroup-1.1.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /Users/jacobwaldor/mambaforge/lib/python3.9/site-packages (from trio~=0.17->selenium) (21.4.0)\n",
            "Collecting outcome\n",
            "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: idna in /Users/jacobwaldor/mambaforge/lib/python3.9/site-packages (from trio~=0.17->selenium) (3.3)\n",
            "Collecting wsproto>=0.14\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /Users/jacobwaldor/mambaforge/lib/python3.9/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /Users/jacobwaldor/mambaforge/lib/python3.9/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
            "\u001b[33mWARNING: Error parsing requirements for pybind11: [Errno 2] No such file or directory: '/Users/jacobwaldor/mambaforge/lib/python3.9/site-packages/pybind11-2.10.0.dist-info/METADATA'\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: wsproto, outcome, exceptiongroup, async-generator, trio, trio-websocket, selenium\n",
            "Successfully installed async-generator-1.10 exceptiongroup-1.1.1 outcome-1.2.0 selenium-4.9.1 trio-0.22.0 trio-websocket-0.10.2 wsproto-1.2.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install selenium"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4fKRuYJJngZ"
      },
      "source": [
        "Download a WebDriver: To interact with a web browser, you need to download a WebDriver that corresponds to the browser you want to use. There are different WebDriver implementations for different browsers like Chrome, Firefox, and Edge. In this guide, we'll be using the Chrome WebDriver.\n",
        "\n",
        "You can download the Chrome WebDriver from the official website: https://sites.google.com/a/chromium.org/chromedriver/downloads.\n",
        "\n",
        "Download the version that corresponds to the version of Chrome you have installed on your computer. Once you've downloaded the WebDriver, extract it to a folder on your computer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pERZMfK3JttR"
      },
      "source": [
        "Set up the environment: In your Python code, you need to import the Selenium WebDriver module and create an instance of the WebDriver. Here's an example code snippet:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tR3Tnu9eJvUe",
        "outputId": "55afe94f-3fd3-4b46-80b3-fcba900ff0db"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/gs/dvcv0qpj3v9gs8djzpflb3mw0000gn/T/ipykernel_2542/2994368104.py:7: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
            "  driver = webdriver.Chrome(chrome_driver_path)\n"
          ]
        }
      ],
      "source": [
        "from selenium import webdriver\n",
        "\n",
        "# Path to the Chrome WebDriver executable\n",
        "chrome_driver_path = \"path-to-webdriver\"\n",
        "\n",
        "# Create a new instance of the Chrome WebDriver\n",
        "driver = webdriver.Chrome(chrome_driver_path)\n",
        "\n",
        "# Navigate to a webpage\n",
        "driver.get(\"https://www.google.com\")\n",
        "\n",
        "# Close the browser window\n",
        "driver.quit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFTRvqeXJxZ-"
      },
      "source": [
        "In this example, the WebDriver navigates to the Google homepage, and then the driver.quit() method is called to close the browser window. Replace the chrome_driver_path variable with the path to the Chrome WebDriver executable that you downloaded in step 3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rS-p_3fKMdQ"
      },
      "source": [
        "That's it! You now have a basic setup for using Selenium in Python. From here, you can use the WebDriver to interact with a webpage, perform user actions, and extract data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBZHR1GeLi7I"
      },
      "source": [
        "#### How to use Selenium to do amazing web scraping!\n",
        "\n",
        "We now provide an example of scraping with Selenium. Scraping with Selenium involves three steps:\n",
        "1.   Set up a WebDriver object to use to navigate the website.\n",
        "2.   Use the WebDriver to navigate to the website.\n",
        "3.   Identify the steps needed to extract the desired information from the webpage. This includes identifying which clicks and other interactions to make and which specific pieces of data to extract.\n",
        "4.   Inspect the HTML/CSS of the webpage to identify the page elements associated with the interactions in step 3. Based on that knowledge, use Selenium to automate interactions with the site."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nykaz8ZAFptw"
      },
      "source": [
        "In this example, we use Selenium to execute a search on the Divar site and extract the search results on the first page. The first step is to set up the WebDriver object as described above. If we'd like, we can run the browser in \"headless\" mode so that we never see it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtS_ANj7Jh75",
        "outputId": "95c64946-fdf1-4ce4-e505-473137cd7162"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/gs/dvcv0qpj3v9gs8djzpflb3mw0000gn/T/ipykernel_2542/639644801.py:15: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
            "  driver = webdriver.Chrome(chrome_driver_path, options=options)\n"
          ]
        }
      ],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.common.by import By\n",
        "\n",
        "# Set up options for the Chrome WebDriver\n",
        "options = webdriver.ChromeOptions()\n",
        "# options.add_argument('--headless')  # Runs Chrome in headless mode\n",
        "\n",
        "# Path to the Chrome WebDriver executable\n",
        "chrome_driver_path = 'path-to-webdriver'\n",
        "\n",
        "# Create a new instance of the Chrome WebDriver\n",
        "driver = webdriver.Chrome(chrome_driver_path, options=options)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1I-StIZGRXh"
      },
      "source": [
        "Now we navigate to the site:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlIAIm4dGTau"
      },
      "outputs": [],
      "source": [
        "# Navigate to the Tasnim News Agency website\n",
        "driver.get(\"https://divar.ir/s/tehran\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IL_ALY15Fn1N"
      },
      "source": [
        "Now that we've navigated to the Divar site, we need to determine the page element associated with the search bar so that we can execute a search. We can do this by right-clicking on the search and clicking \"Inspect Element.\" We look for tags such as \\<input\\>, \\<form\\>, or specific classes or IDs associated with the search bar. The search bar element might also have a placeholder attribute or specific styling properties. We find that there are two \\<input\\> tags and the class attribute of the \\<input\\> element is set to \"kt-nav-text-field__input\". Therefore, we can use the class name of the input to identify it and input the desired information:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0R0aaVHaIbcG"
      },
      "outputs": [],
      "source": [
        "search_input = driver.find_element(by=webdriver.common.by.By.CLASS_NAME, value=\"kt-nav-text-field__input\")\n",
        "search_input.send_keys(\"hello\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5K49sG3JwG0"
      },
      "source": [
        "Now that we've inputted our search query, we can press the \"return\" key and wait up to 10 seconds for the search results to load."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-PXlCjsJeLx"
      },
      "outputs": [],
      "source": [
        "search_input.send_keys(Keys.RETURN)\n",
        "# Wait for the search results to load\n",
        "wait = WebDriverWait(driver, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XfuV5HqKBGV"
      },
      "source": [
        "To extract the search results on the first page, we need to determine the page elements associated with them. We find that \n",
        "\\<h2 class=\"kt-post-card__title\">ست آچار کیانلی مدل Hello Phillips\\</h2\\> contains the title of one of the search results.\n",
        "\n",
        "We can try identifying all text associated with the class=\"kt-post-card__title\" and see if that captures the desired information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzrZQOqDKFu9"
      },
      "outputs": [],
      "source": [
        "elements = driver.find_elements(by=webdriver.common.by.By.CLASS_NAME, value = \"kt-post-card__title\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we extract text from each of the elements and display it."
      ],
      "metadata": {
        "id": "GW1jaBOgewaR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxxWGgzqaslh"
      },
      "outputs": [],
      "source": [
        "text_list = [element.text for element in elements]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcyAVvEQasli",
        "outputId": "0223f035-1d76-4caf-ef94-e7c876879c0a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['پک کامل دستگاه تتو پن Fk hello با تمامی تجهیزات',\n",
              " '',\n",
              " 'ست آچار کیانلی مدل Hello Phillips',\n",
              " '',\n",
              " 'کالسکه Hello baby کم کارکرد',\n",
              " '',\n",
              " 'هشداردهنده صوتی Hello well com',\n",
              " '',\n",
              " 'ساعت چرمی Hello kitty',\n",
              " '',\n",
              " 'دستگاه تتو پن مدل HELLO زاین',\n",
              " '',\n",
              " 'فلاسکhello dream',\n",
              " '',\n",
              " 'لباس ۳ تیکه نوزادی برند ( Hello beyby )',\n",
              " '',\n",
              " 'لباس سرهمی نوزادی پسرانه برند ( Hello beyby )',\n",
              " '',\n",
              " 'لباس سرهمی نوزادی برند ( Hello beyby )',\n",
              " '',\n",
              " 'عروسک سگ بالشتی طرح hello',\n",
              " '',\n",
              " 'تی شرت آستین کوتاه و شلوار جنس ترک طرح Hello',\n",
              " '']"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_list"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hooray! We see that we have obtained a list of titles from the webpage.\n",
        "\n",
        "You now have a taste of the power of Selenium. I hope that this opens the door to powerful and creative projects for you!"
      ],
      "metadata": {
        "id": "Xk1hVmDze3IM"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}